{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 5\n",
    "## Name: Nihal Patel\n",
    "## Student ID: 8945100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will Load the diabetes dataset fromsklearn_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF = load_diabetes()\n",
    "X, y = diabetesDF.data, diabetesDF.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will Split the data into training and testing sets i.e. test_size as 20% and train_size as 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will perform cross-validation on polynomial models from degree 0 to 8 so using range function which will take values from 0 to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(9) \n",
    "results = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # We will calculate the r2 score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # We will calculate the mean absolute error score\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # We will calculate the mean absolute percentage error score\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) \n",
    "    \n",
    "    results.append((degree, r2, mae, mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will construct a DataFrame to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Degree', 'R-Squared', 'MAE', 'MAPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will calculate the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Table:\n",
      "         R-Squared             MAE          MAPE    \n",
      "             mean std        mean std      mean std\n",
      "Degree                                             \n",
      "0       -0.011963 NaN   64.006461 NaN  0.627918 NaN\n",
      "1        0.452603 NaN   42.794095 NaN  0.374998 NaN\n",
      "2        0.415640 NaN   43.581693 NaN  0.382857 NaN\n",
      "3      -15.447423 NaN  182.247191 NaN  1.653290 NaN\n",
      "4      -26.728083 NaN  261.667144 NaN  2.300991 NaN\n",
      "5      -25.992920 NaN  255.968358 NaN  2.270202 NaN\n",
      "6      -25.975743 NaN  255.908618 NaN  2.269658 NaN\n",
      "7      -25.975478 NaN  255.906822 NaN  2.269649 NaN\n",
      "8      -25.975557 NaN  255.907119 NaN  2.269653 NaN\n"
     ]
    }
   ],
   "source": [
    "mean_std_df = results_df.groupby('Degree').agg({\n",
    "    'R-Squared': ['mean', 'std'],\n",
    "    'MAE': ['mean', 'std'],\n",
    "    'MAPE': ['mean', 'std']\n",
    "})\n",
    "\n",
    "# We will display the summary table\n",
    "print(\"Summary Table:\\n\",mean_std_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the summary table, for each degree there is only a single data point (NaN) available for evaluation. This can be caused due to a specific characteristics of the dataset or can be considered on the basis of how the data splitting is done in the process of cross-validation. The data may be very sparse for some certain degrees. The reasons may be as below:\n",
    "1. Best Model Identification: We can identify the model which will showcase the best performance based on R-square, MAE and MAPE metrics. Based on the mean R-Squared, MAE and MAPE metrics, we can see that the model with degree 1 (quadratic polynomial) has the highest R-squared (0.45) and the lowest MAE (42.79) and MAPE (0.37). Hence, polynomial model can be seen performing well.\n",
    "\n",
    "Why we choose the specific model (Degree 1):\n",
    "R-Squared: This model with degree 1 has the highest R-squared value which is indicating that it is explaining about a significant portion of the variance in the data. This suggests that the quadratic model is fitting the data in a much better way.\n",
    "\n",
    "MAE and MAPE: The model with degree 1 is also having the lowest Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). This is indicating that it is having the smallest average absolute difference between predicted and actual values for the predictive accuracy.\n",
    "\n",
    "2. Additional analysis and interpretation of the models' performances:  \n",
    "The insights for the required metrics can be explored further if an analysis can provide atleast one relevant insight about the choice of the best model, or about characteristics of the chosen one (ex: considering an analysis of in which instances it is failing). It is very important to note that for a higher degree models (ex. degrees 3 to 8), the R-Squared values are seen as significantly negative. This exhibits that these models are performing very poorly and may overfit to the training data. This is because of the models which become very complex and capture noise in the data.\n",
    "\n",
    "Hence, it's recommended to use the quadratic model (degree 1) to make predictions, as it displays a good balance between model complexity and predictive performance. However, it is crucial to consider other factors like interpretability and computational resources when choosing a final model. The advanced techniques like regularized regression can also be beneficial for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
